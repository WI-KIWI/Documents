{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor wrangling with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Autor Zilong Zhao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data wrangling is a daily job for data scientists. In this notebook, we do some softmax computation task as an example to show how to manipulate a tensor with TensorFlow framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax function, or normalized exponential function can be used to represent a categorical distribution, i.e. for probability computation in probability theory. \n",
    "\n",
    "Mathematically the softmax function can be written as:\n",
    "\n",
    "$$\\forall x \\in \\mathbb{R}, ~~~\\sigma (x) \\in [0,1]$$\n",
    "\n",
    "and the function is given by\n",
    "$$\\sigma (\\mathbf {x} )_{j}={\\frac {e^{x_{j}}}{\\sum _{k=1}^{K}e^{x_{k}}}} \\mathrm{~~~~for~~~~} j=1,...,K$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The softmax calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a vector $\\mathbf{x}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = [i for i in range(0, 20, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   2.   4.   6.   8.  10.  12.  14.  16.  18.]\n",
      "[  1.31688243e-08   9.73051826e-08   7.18993476e-07   5.31268324e-06\n",
      "   3.92557122e-05   2.90062657e-04   2.14328920e-03   1.58368852e-02\n",
      "   1.17019631e-01   8.64664614e-01]\n"
     ]
    }
   ],
   "source": [
    "# compute softmax for vector x \n",
    "import tensorflow as tf\n",
    "\n",
    "x_tensor = tf.Variable(x, dtype=tf.float32)\n",
    "x_softmax = tf.nn.softmax(x_tensor)\n",
    "init = tf.global_variables_initializer()                                    \n",
    "with tf.Session() as s:                                                 \n",
    "    s.run(init)                                                         \n",
    "    print(s.run(x_tensor))   \n",
    "    print(s.run(x_softmax))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if you want to calculate the probability for the first five classes only? Of course, here you could just rewrite your input vector as $x=[0, 2, 4, 6, 8]$. But if we are in the situation, that the x_tensor comes directly from TensorFlow computation, such as the output of a ten-class classification neural network, how can we use TensorFlow to manipulate the data with tensor format?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TensorFlow for wrangling task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  2.  4.  6.  8.]\n",
      "[  2.90075870e-04   2.14338675e-03   1.58376060e-02   1.17024951e-01\n",
      "   8.64703953e-01]\n"
     ]
    }
   ],
   "source": [
    "# select the first five elements in tensor\n",
    "import tensorflow as tf\n",
    "\n",
    "x_tensor = tf.Variable(x, dtype=tf.float32)\n",
    "x_tensor_new = tf.gather(x_tensor, [0, 1, 2, 3, 4])\n",
    "x_softmax = tf.nn.softmax(x_tensor_new)\n",
    "init = tf.global_variables_initializer()                                    \n",
    "with tf.Session() as s:                                                 \n",
    "    s.run(init)                                                         \n",
    "    print(s.run(x_tensor_new)) \n",
    "    print(s.run(x_softmax))  \n",
    "    proba = s.run(x_softmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the probability computation\n",
    "proba.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary and outlook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see here, we used the tf.gather() function and passed the index list $[0,1,2,3,4]$ to x_tensor_new to select the first five elements from the x_tensor. With such function, we don't need to transform a tensor to numpy array for data manipulation. In fact, computing with tensor by using TensorFlow could save us time for a large scale computation task. \n",
    "\n",
    "Besides neural network modelling, TensorFlow has a rich library of functions for data wrangling, or tensor wrangling more precisely. An overview could be found here: https://www.tensorflow.org/api_docs/python/tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
